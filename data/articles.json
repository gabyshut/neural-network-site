[
    {
        "name": "YaLM 2",
        "description": "Языковая модель от Яндекса (весной 2024 года открыта в версии YaLM 2 13B). Поддерживает генерацию текста, программирование, диалоги.",
        "text": "YaLM 2 — это вторая версия крупной языковой модели, разработанной компанией «Яндекс». Она входит в число самых мощных открытых нейросетей, созданных в России, и ориентирована на обработку естественного языка, генерацию текста, ответ на вопросы, написание кода и другие интеллектуальные задачи. Вышедшая в 2024 году, YaLM 2 особенно привлекает внимание тем, что была опубликована в открытом доступе (весной — модель с 13 миллиардами параметров), что делает её значимым шагом в развитии отечественного ИИ.\nС практической стороны, пользоваться YaLM 2 можно как через веб-интерфейс, так и путём развертывания модели локально или в облаке, если есть соответствующие вычислительные мощности. Яндекс предоставляет доступ к API, а также исходный код и веса модели через Hugging Face, что даёт возможность разрабатывать собственные продукты, встраивать модель в чат-ботов, голосовых помощников, интеллектуальные редакторы и другие приложения. Для работы с моделью можно использовать библиотеки вроде transformers от Hugging Face, что делает её интеграцию понятной для специалистов, знакомых с Python и машинным обучением.\nНа более глубоком уровне YaLM 2 представляет собой автоподсказывающий трансформер (causal transformer), аналогичный архитектуре GPT. Модель обучалась на больших объёмах текстовых данных, преимущественно на русском языке, но с включением английского и других языков, что делает её мультилингвальной, хотя и с приоритетом на русскоязычные задачи. Она умеет продолжать текст по заданному началу, обобщать информацию, формулировать ответы на вопросы, писать статьи и даже программировать. Её обучение происходило на текстах из новостей, энциклопедий, форумов, репозиториев кода, а также на открытых наборах данных, что дало модели достаточно широкий кругозор, хотя и не сравнимый по охвату с GPT-4 или Claude 3.\nС точки зрения архитектуры, YaLM 2 использует механизмы внимания (attention) и позиционной энкодировки, характерные для трансформеров. Яндекс не раскрыл все подробности архитектуры, но известно, что модель была оптимизирована под российские инфраструктурные реалии — например, она может быть запущена на отечественных суперкомпьютерах (в частности, Yandex DataSphere и облачные кластеры). Интересным фактом является то, что YaLM 2 была протестирована и адаптирована с учётом русскоязычных задач, таких как обработка юридических документов, генерация контента для СМИ, помощь в обучении и консультации по программированию.\nКроме того, YaLM 2 активно используется для исследований в области ИИ и лингвистики. Открытость модели позволяет другим исследователям повторять эксперименты, проверять качество генерации, адаптировать её под специфические задачи — например, чат-ботов для бизнеса, юридических помощников или ассистентов для студентов. В отличие от многих западных моделей, у которых API ограничен и код закрыт, YaLM 2 предлагает редкую возможность экспериментов на полном уровне: можно тонко настраивать модель, дообучать её на своих данных, исследовать внутренние механизмы принятия решений.\nИнтересно, что команда Яндекса сделала акцент не только на продуктивности, но и на этике использования. Модель YaLM 2 оснащена фильтрами, которые помогают избегать генерации токсичных, оскорбительных или фейковых материалов. Хотя в открытой версии фильтры ограничены, корпоративная версия модели встраивается в экосистему Яндекса с соблюдением строгих правил безопасности и конфиденциальности.\nНаконец, стоит отметить, что YaLM 2 стала символом усилий России по созданию суверенного искусственного интеллекта — модели, которая может функционировать независимо от внешних технологических поставщиков, но при этом соответствует современным мировым стандартам. Появление такой модели особенно важно в условиях санкций и ограничения доступа к западным технологиям. В перспективе YaLM 2 может стать основой для будущих версий, возможно, мультимодальных моделей (тексты + изображения + аудио), и уже сегодня используется в продуктах Яндекса, включая поисковые подсказки, голосового помощника Алису и сервисы для бизнеса.",
        "source": "https://alice.yandex.ru/",
        "media": [
            {
                "type": "iframe",
                "src": "https://vkvideo.ru/video_ext.php?oid=-209631091&id=456239041&hd=2&autoplay=0",
                "title": "Обзор YandexGPT ПРО"
            },
            {
                "type":"image",
                "src": "media/yalm2screenshot1.jpeg",
                "alt": "Пример диалога с Алисой."
            },
            {
                "type":"image",
                "src": "media/yalm2screenshot2.png",
                "alt": "Пример диалога с Алисой через веб-браузер."
            }
        ]
    },
    {
        "name": "SberGPT и GigaChat",
        "description": "Серия моделей от Сбера. GigaChat — мультимодальная модель, способная обрабатывать текст, изображения, программный код. Работает на Christofari Neo.",
        "text": "SberGPT и GigaChat — это линейка крупных языковых моделей, разработанных экосистемой Сбера. Они являются флагманскими примерами отечественных нейросетей, способных решать широкий спектр интеллектуальных задач: от генерации текстов и программирования до анализа данных и обработки изображений. Если SberGPT представляет собой классическую LLM (large language model), ориентированную на работу с текстом, то GigaChat — это мультимодальная система, сочетающая текстовые, графические и кодовые возможности, и в каком-то смысле выступающая ответом на GPT-4o, Gemini и Claude.\nРаботать с этими моделями можно через официальную платформу — веб-интерфейс для диалогового общения, а также через API, который предоставляет доступ к нейросети разработчикам и компаниям. Для получения доступа достаточно зарегистрироваться с подтверждённой учётной записью на Госуслугах, хотя в рамках программ поддержки образования и науки возможны иные формы доступа. Сбер активно продвигает GigaChat как отечественный аналог ChatGPT, и на практике функциональность действительно сравнима: модель умеет вести диалог в естественном языке, писать статьи, отвечать на вопросы, составлять резюме, генерировать стихи, переводить тексты, анализировать таблицы, писать код, а также генерировать изображения по текстовому описанию с помощью подключённого генеративного модуля Kandinsky.\nЧто касается технической стороны, в основе SberGPT лежит архитектура трансформера, вдохновлённая GPT-3, но адаптированная под русскоязычные данные. Обучение происходило на масштабных корпусах текстов, включая научные, технические, художественные, юридические и новостные источники. Модель была дообучена и донастроена с использованием RLHF (обучения с подкреплением на человеческой обратной связи), что улучшило качество ответов и сделало их более естественными. GigaChat использует более продвинутые версии этой архитектуры и интегрирует мультимодальность — способность воспринимать и обрабатывать изображения. Также поддерживаются вложенные вложения (инлайн изображения, таблицы, диаграммы), что особенно важно для профессионального использования в бизнесе и образовании.\nМодель разворачивается на российском суперкомпьютере Christofari Neo, одном из самых мощных в стране. Это позволяет обрабатывать запросы в реальном времени и обслуживать большое количество пользователей одновременно. Благодаря этому GigaChat был одним из первых отечественных ИИ-сервисов, выдержавших массовую нагрузку во время запуска, и продолжает активно развиваться с новыми функциями, в том числе поддержкой PDF-документов, таблиц Excel, обработки кода и изображений.\nСбер также позаботился о вопросах безопасности и регулирования: в модели встроены фильтры, блокирующие токсичный, опасный и нежелательный контент. Это особенно важно при внедрении GigaChat в крупные компании, образовательные учреждения и государственные органы. Более того, платформа соответствует требованиям российского законодательства о персональных данных и информационной безопасности, что выгодно отличает её от зарубежных аналогов, где обработка данных часто происходит за пределами юрисдикции пользователя.\nИнтересной особенностью GigaChat стало внимание к программированию. Модель умеет писать, объяснять и исправлять код на разных языках, включая Python, JavaScript, C++, Java и даже запросы к базам данных (SQL). Для многих задач она может быть использована как помощник разработчика, предлагающий рабочие решения и объяснения. Также GigaChat обучен на русскоязычной документации и терминологии, что делает его особенно удобным для пользователей, не работающих на английском языке.\nС точки зрения стратегического значения, GigaChat и SberGPT стали частью государственной инициативы по цифровому суверенитету. Их развитие неразрывно связано с задачей импортозамещения в ИТ-сфере и созданием конкурентоспособных решений на основе отечественных вычислительных платформ и инфраструктуры. Сбер активно публикует научные статьи о своих моделях, а часть моделей, включая ruGPT-3 и ruT5, доступна в открытом доступе на Hugging Face, что позволяет исследователям и энтузиастам применять их в собственных проектах.\nТаким образом, GigaChat представляет собой не просто нейросеть, а комплексную интеллектуальную платформу, сочетающую силу языковых моделей, мультимодальность, удобный пользовательский интерфейс, совместимость с российским ИТ-законом и ориентацию на практическое применение в самых разных сферах — от образования и творчества до программирования, аналитики и документооборота. В ближайшем будущем можно ожидать ещё более тесную интеграцию GigaChat с другими продуктами Сбера (например, СберМаркет, СберЗдоровье, СберОбразование), а также расширение возможностей генерации речи, видео и более глубокую работу с персонализированными данными.",
        "source": "https://giga.chat/",
        "media": [
            {
                "type": "iframe",
                "src": "https://vkvideo.ru/video_ext.php?oid=-223796864&id=456239030&hd=2&autoplay=0",
                "title": "Обзор GigaChat"
            },
            {
                "type": "image",
                "src": "media/sberGPTscreenshot1.png",
                "alt": "Главная страница."
            },
                        {
                "type": "image",
                "src": "media/sberGPTscreenshot2.png",
                "alt": "Функции инструменты SberGPT."
            },
                        {
                "type": "image",
                "src": "media/sberGPTscreenshot3.png",
                "alt": "Голосовая функция в SberGPT."
            },
                        {
                "type": "image",
                "src": "media/sberGPTscreenshot4.png",
                "alt": "Открытка с помощью нейросети SberGPT."
            }
        ]
    },
    {
        "name": "Neuronet",
        "description": "Государственная инициатива по созданию и обучению отечественных нейросетей, включая модели для речевой аналитики, CV и LLM.",
        "text": "Neuronet — это не просто одна нейросеть, а масштабная инициатива, развиваемая Ассоциацией участников рынка искусственного интеллекта (ИИ-ассоциацией) в России. Проект «Neuronet» направлен на формирование отечественной экосистемы в сфере искусственного интеллекта, объединяя под собой множество компонентов: инфраструктуру, модели, инструменты разработки, прикладные сервисы и стандарты. Его конечная цель — создать технологическую базу, позволяющую России быть независимой от зарубежных ИИ-решений и при этом идти в ногу с мировыми трендами в области генеративного ИИ, компьютерного зрения, обработки речи и машинного перевода.\nВ отличие от конкретных моделей вроде GigaChat или YaLM 2, Neuronet — это инфраструктурная платформа, которая аккумулирует развитие ИИ-решений на российской технологической базе. В неё входят и собственные нейросетевые модели (в том числе языковые и мультимодальные), и платформы для их обучения, и сервисы для их использования. Проект активно поддерживается государством в рамках стратегии цифрового суверенитета и считается «песочницей» для инноваций в ИИ: здесь экспериментируют и крупные компании, и научные институты, и стартапы, предлагая модели и решения, адаптированные под локальные задачи и языковую среду.\nОдной из ключевых особенностей Neuronet является модульность. Это означает, что различные нейросетевые компоненты — генерация текста, синтез речи, распознавание изображений, анализ данных — могут быть встроены в одну систему или использоваться по отдельности. Например, в рамках Neuronet уже созданы модели для автоматического перевода с иностранных языков на русский (и обратно), генерации программного кода, классификации юридических и медицинских документов, распознавания объектов на видео, а также мультимодальные ИИ, способные комбинировать текст, изображение и речь.\nОсобое внимание уделяется обучающим наборам данных, которые разрабатываются и верифицируются внутри страны. Это один из самых важных аспектов, потому что многие западные модели обучены на англоязычных источниках и плохо справляются с русским контекстом или нормативной лексикой. Neuronet, напротив, собирает специализированные датасеты из источников, которые отражают реалии российского языка, культуры, права и образования. Это позволяет моделям точнее обрабатывать запросы пользователей, адаптироваться под корпоративные и государственные задачи, а также минимизировать риски ошибок и искажений.\nПлатформа также предлагает визуальные и программные инструменты для создания и тонкой настройки собственных моделей. Разработчики могут использовать среды вроде Neuronet Studio или SDK для интеграции ИИ в свои приложения. В некоторых сценариях доступны возможности дообучения модели на закрытых данных — например, в медицинских учреждениях или внутри компаний. В этом смысле Neuronet ориентирован не только на широкую публику, но и на профессиональное и корпоративное применение.\nС технической точки зрения, модели, создаваемые в рамках Neuronet, базируются на открытых архитектурах (вроде трансформеров), но адаптированы под отечественные вычислительные мощности и стандарты. Многие из них совместимы с облачными и кластерными решениями на базе российских суперкомпьютеров и ЦОДов. Это позволяет масштабировать модели на уровне государства и внедрять их в ключевые отрасли: здравоохранение, транспорт, образование, промышленность.\nВ 2024–2025 годах Neuronet стал заметным участником на рынке благодаря ряду пилотных внедрений: от голосовых помощников для госуслуг и поддержки колл-центров до автоматического анализа юридических документов и генерации обучающих материалов. Проект поддерживается не только ИИ-ассоциацией, но и Минцифры, Минпромторгом и ведущими ИТ-компаниями, в том числе Сбером, Яндексом, VK и МФТИ.\nИнтересный факт: в рамках платформы активно обсуждается идея «цифрового доверия» — включение механизмов прозрачности, аудита и этической фильтрации в каждую модель, чтобы избежать дискриминации, искажения фактов и недопустимой генерации. Neuronet строится как безопасная, верифицируемая и регулируемая среда, в которой каждая модель может быть оценена по понятным критериям. Это важно в контексте растущих опасений относительно неконтролируемых ИИ и deepfake-технологий.\nТаким образом, Neuronet — это опорная структура для всего российского искусственного интеллекта. Он не конкурирует напрямую с конкретными чат-ботами, а создаёт основу, на которой такие боты и сервисы могут строиться. Это стратегический и научно-технологический проект, объединяющий индустрию, государство и науку вокруг одной цели: создать устойчивую, безопасную, открытую и по-настоящему отечественную платформу ИИ.",
        "source": "https://neuro.net/ru/",
        "media": [
            {
                "type": "image",
                "src": "media/neuronetScreenshot1.png",
                "alt": "Главная страница."
            },
            {
                "type": "image",
                "src": "media/neuronetScreenshot2.png",
                "alt": "Продукты Neuronet."
            }
        ]
    },
    {
        "name": "ChatGPT",
        "description":"Чат-бот с генеративным искусственным интеллектом, разработанный компанией OpenAI.",
        "text": "ChatGPT — это флагманский ИИ-продукт компании OpenAI, основанный на линейке моделей GPT (Generative Pre-trained Transformer). На момент 2025 года в публичном доступе наиболее актуальными версиями являются GPT-4, а также его улучшенная мультимодальная разновидность GPT-4o, где «о» означает «omni» — универсальный. Эти модели представляют собой один из самых продвинутых ИИ-инструментов в мире, способный не просто генерировать текст, но и понимать речь, изображение, таблицы, код, и — в случае GPT-4o — даже работать в режиме реального времени с голосом и эмоциями.\nChatGPT стал глобальным феноменом, оказав влияние на образование, бизнес, творчество и программирование. В его основе лежит трансформерная архитектура, впервые представленная в работе Google в 2017 году, но значительно доработанная и масштабированная OpenAI. Модель GPT обучается в два этапа: сначала на огромных объёмах текстов с открытого интернета (обучение с учителем), а затем — с участием людей, которые оценивают ответы и помогают модели лучше соответствовать ожиданиям (обучение с подкреплением от обратной связи человека, RLHF). Такой подход позволил создать систему, которая может не просто отвечать грамотно, но и соблюдать стиль, учитывать контекст и вести диалог в сложных ситуациях.\nЧтобы пользоваться ChatGPT, достаточно зайти на сайт и создать аккаунт. Бесплатные пользователи получают доступ к GPT-3.5 — быстрой и мощной, но более ограниченной версии. Платные подписчики (ChatGPT Plus) получают доступ к GPT-4 или GPT-4o. GPT-4o в частности позволяет не только писать тексты, но и анализировать изображения, работать с файлами, вести разговор голосом, распознавать таблицы, делать расчёты и помогать в сложных когнитивных задачах. Пользователь может загружать PDF-документы, фотографии, диаграммы, записывать голосовые сообщения, и модель отвечает в реальном времени, как собеседник.\nGPT-4o — это важный шаг вперёд в направлении мультимодальности. Она способна воспринимать зрение, слух и текст одновременно и свободно переключаться между ними. В демо-примерах от OpenAI модель играла в города голосом, распознавала эмоции по интонации, обсуждала графики, находила ошибки в коде на фотографии и даже давала советы по одежде на основе фото пользователя. При этом её скорость реакции приближается к человеческой: задержка в ответах составляет всего около 300 миллисекунд — как у живого собеседника.\nС точки зрения «внутренней кухни», GPT-4o — это не просто большая модель, а универсальный обученный трансформер, который был с самого начала натренирован на текстах, изображениях, аудио и коде. В отличие от более старых моделей, которые объединяли несколько отдельных сетей (например, язык + зрение + речь), GPT-4o изначально «вырос» как цельный организм с общим восприятием. Это позволило устранить необходимость в «посредниках» между модальностями и добиться естественного, связного поведения, когда, скажем, эмоция в голосе влияет на стиль ответа, а увиденное на изображении становится частью смыслового поля.\nИнтересный момент: GPT-4 — как и его более ранние версии — это закрытая модель. OpenAI не раскрывает точные параметры, включая количество слоёв, весов или данных, на которых она обучалась. Однако известно, что GPT-4 была обучена на смешанных языковых и кодовых данных, включая программирование, научные тексты, художественные произведения и диалоги. Модель «учит» не факты напрямую, а закономерности языка, и потому способна создавать новые тексты по заданным шаблонам, придумывать истории, генерировать сценарии, стихи, музыку (с помощью внешних плагинов), и даже решать сложные математические и логические задачи.\nСфера применения ChatGPT — практически неограниченная. Студенты используют его для помощи в учёбе, копирайтеры — для генерации контента, преподаватели — для создания дидактических материалов, программисты — для помощи с кодом. С помощью встроенного кодового интерпретатора (Python-песочницы) модель может выполнять вычисления, строить графики, анализировать CSV-файлы и даже разрабатывать простые приложения. GPT-4o делает это ещё быстрее и с возможностью уточнять запрос голосом или добавляя визуальные подсказки.\nМодель ChatGPT продолжает развиваться в сторону персонализации: с 2024 года пользователи могут создавать «Custom GPTs» — индивидуальные боты с собственным стилем, поведением и даже знаниями. Их можно обучить работать в рамках конкретной ниши — например, в праве, медицине, маркетинге — и интегрировать в бизнес или учебные платформы. Через GPT Store можно публиковать такие версии и делиться с другими.\nС точки зрения этики и безопасности, OpenAI внедрила множество фильтров, инструкций и ограничений: ChatGPT не генерирует опасный контент, старается избегать политических тем, не даёт советов по вредоносным действиям. Однако критики всё же указывают на случаи, когда модель давала ложные сведения или «галлюцинировала» — выдумывала факты с убедительным видом. Тем не менее, с каждой новой версией уровень достоверности и адекватности растёт.\nТаким образом, ChatGPT (особенно в версии GPT-4o) — это уже не просто текстовый бот, а полноценный цифровой ассистент, сочетающий возможности анализа, диалога, генерации и визуального восприятия. Он находит применение в самых разных областях — от корпоративной автоматизации и аналитики до детского образования и творческих проектов. Благодаря своему «человеческому» поведению, высокой скорости и широте знаний, ChatGPT стал символом новой эры в развитии искусственного интеллекта — эры, где граница между человеком и машиной становится всё более тонкой.",
        "source": "https://chatgpt.com/",
        "media": [
            {
                "type": "iframe",
                "src": "https://vkvideo.ru/video_ext.php?oid=-226922990&id=456239017&hd=2&autoplay=0",
                "title": "Обзор ChatGPT"
            },
            {
                "type": "image",
                "src": "media/chatGPTscreenshot1.jpg",
                "alt": "Функции ChatGPT."
            },
                        {
                "type": "image",
                "src": "media/chatGPTscreenshot2.png",
                "alt": "Пример диалога с ChatGPT."
            },
                        {
                "type": "image",
                "src": "media/chatGPTscreenshot3.png",
                "alt": "Функции ChatGPT."
            }
        ]
    },
    {
        "name": "Claude 3",
        "description":"Cемейство больших языковых моделей (LLM), разработанных компанией Anthropic.",
        "text": "Claude 3 — это семейство передовых языковых моделей, разработанных компанией Anthropic, которая была основана выходцами из OpenAI и позиционирует себя как разработчик «этичного ИИ нового поколения». Модель названа в честь Клода Шеннона, основателя теории информации, и с самого начала создавалась как альтернатива GPT-моделям, с акцентом на безопасность, интерпретируемость и долгосрочную надёжность. В 2024 году вышла третья версия, Claude 3, представленная сразу в трёх модификациях: Claude 3 Haiku (лёгкая и быстрая), Claude 3 Sonnet (средняя по мощности) и Claude 3 Opus (самая мощная, сопоставимая с GPT-4 и превосходящая его по ряду тестов).\nClaude 3 отличается высоким качеством диалога, мягкой, «человечной» подачей, отличной памятью и способностью поддерживать длинные, осмысленные беседы. Одна из её сильных сторон — способность глубоко рассуждать, особенно в философских, этических и креативных задачах. Она прекрасно справляется с анализом текста, аргументацией, логикой, объяснением концепций и стилизацией текста под конкретного автора. Модель демонстрирует высокий уровень «мягкого интеллекта»: умеет не только отвечать правильно, но и делать это с вежливостью, сочувствием и вниманием к деталям. В этом плане Claude 3 ближе к человеку, чем, например, GPT-4, особенно в эмоционально насыщенных беседах.\nС технической точки зрения Claude 3 — это мультимодальная модель, умеющая анализировать изображения, диаграммы, таблицы, PDF-документы, но пока не имеет голосового ввода в интерфейсе. Она способна обрабатывать контекст длиной до 200 000 токенов, что позволяет ей удерживать в памяти сотни страниц текста — от книг до технической документации. Эта способность особенно ценна в юридических, научных, образовательных и деловых задачах. Пользователи могут загружать большие файлы и просить Claude анализировать их, делать выводы, формировать резюме или даже искать несостыковки.\nClaude 3 также успешно справляется с программированием: она пишет код на Python, JavaScript, C++, Go, и даёт развёрнутые объяснения, особенно если просить её обучать «как преподавателя». По скорости в задачах генерации кода Opus и Sonnet иногда превосходят GPT-4, особенно в логике и чистоте кода. Модель может выполнять тонкий анализ структуры, объяснять, где и почему возникли ошибки, и предлагать читаемые, лаконичные решения. При этом, в отличие от многих других моделей, Claude 3 реже «галлюцинирует», то есть не выдумывает информацию без повода, а также охотно признаёт, когда чего-то не знает.\nЧто особенно выделяет Claude 3 среди других моделей — это принципы «конституционного ИИ», которые были заложены в её разработку. Вместо жёсткой фильтрации, как у OpenAI или Google, Anthropic обучает свою модель следовать определённому «этическому кодексу», который задаёт приоритеты: быть честной, доброжелательной, непредвзятой, избегать манипуляций и дискриминации. Эта «конституция» — список принципов, составленных людьми — помогает модели оставаться объяснимой и этически устойчивой, даже при генерации чувствительного контента. Claude 3 обычно избегает давать категоричные суждения, предпочитая объяснять разные точки зрения и вести аргументированный диалог.\nИнтерфейс Claude доступен через claude.ai и интегрируется в корпоративные продукты, например, через Amazon Bedrock или в платформу Notion. Бесплатные пользователи получают доступ к Claude 3 Sonnet, платная версия включает Opus и дополнительные функции. В России официальный доступ к Claude 3 ограничен, так как Anthropic пока не предоставляет свои сервисы для аккаунтов с российскими номерами или IP-адресами. Однако некоторые разработчики обходят это ограничение через VPN и регистрацию в других регионах. Также Claude можно встретить как встроенную модель в западных платформах, например, на сайте Quora в сервисе Poe.\nИнтересный факт: Claude 3 не просто обучена на текстах — она «воспитана» как партнёр, способный к эмпатии и моральному суждению. В бета-тестах пользователи описывали её как «друга, с которым хочется поговорить», и сравнивали по мягкости подачи с психологом. В корпоративной среде модель особенно хорошо проявила себя в написании деловой переписки, подготовке отчётов, обучающих материалов и даже в разработке бренд-стратегий. Её стиль — вежливый, логичный, чуть академичный — делает её удобным инструментом как для инженеров, так и для гуманитариев.\nВ целом, Claude 3 — это интеллектуальный собеседник нового уровня: глубокий, спокойный, адаптивный. В нём сочетается мощность современных языковых моделей и чёткая философия доверия, прозрачности и диалога. Он не стремится быть просто машиной, которая выдает правильный ответ — он стремится быть партнёром в рассуждении, помощником в сложной задаче и участником вдумчивого разговора.",
        "source": "https://minitoolai.com/Claude-3/",
        "media": [
            {
                "type": "iframe",
                "src": "https://vkvideo.ru/video_ext.php?oid=-207391732&id=456239078&hd=2&autoplay=0",
                "title": "Обзор Claude 3.5"
            },
            {
                "type": "image",
                "src": "media/claude3screenshot1.png",
                "alt": "Главная страница."
            }
        ]
    },
        {
        "name": "Gemini 1.5",
        "description":"Языковая и мультимодальная модель с высокой памятью, интеграцией в экосистему Google.",
        "text": "Gemini 1.5 — это новое поколение мультимодальной языковой модели от Google DeepMind и Google Research, представленное в феврале 2024 года. Mодель вышла в двух вариантах: Pro — более крупном и мощном, и Flash — облегчённом и быстром. Главная инновация — способность обрабатывать самый длинный контекст из существующих: стандартный Pro охватывает 128 000 токенов, а в приватном превью — до 1 000 000 токенов, что эквивалентно примерно одному часу видео, 11 часам аудио или сотням тысяч строк кода.\nТехнологическая основа Gemini 1.5 — архитектура Mixture‑of‑Experts (MoE). Это означает, что вместо единой монолитной сети модель обращается к узкому «экспертному» блоку, оптимально подходящему для текущего запроса. Такой подход делает Pro‑версию экономичной в вычислениях и эффективной по качеству. Модель Pro показывает результаты уровня Gemini Ultra 1.0 при значительно меньших вычислительных затратах; Flash‑версия была оптимизирована для ускорения с небольшой потерей точности.\nВажное преимущество — возможность работы с разными типами входных данных: это не просто текстовые токены, но и изображения, аудио, видео и код. Gemini 1.5 демонстрирует выдающиеся результаты в задачах с длинным контекстом: суммирование книг, анализ видео, решение программных задач в огромных проектах, поиск «иголки в стоге сена» и даже обучение структуре малоизвестных языков прямо внутри контекста.\nВ тестах модель обходит Gemini 1.0 на 87 % задач и превосходит многие аналоги, включая GPT‑4 Turbo и Claude 3. Она особенно сильна в вопросах математики и логики — есть доказательства, что специализированные версии могут обойти даже OpenAI в задачах MATH и IMO Bench. Кроме того, MoE делает модель значительно дешевле в использовании: на Reddit обсуждают, что она может быть в ~20 раз экономичнее GPT‑4.\nС точки зрения практики, доступна она ограниченно. Pro‑версия доступна в AI Studio и Vertex AI по приглашениям для разработчиков и корпоративных клиентов, Flash‑версия постепенно разворачивается для более широкой аудитории, в том числе через сервис Poe. Для обычных пользователей доступна бесплатная версия Gemini, основанная на 1.5 Flash, хотя без Pro‑возможностей.\nЧто касается доступности в России, официального выпуска Gemini 1.5 для российских пользователей на данный момент нет. Как и многие сервисы Google AI, он блокирован в ряде регионов, включая Россию и страны ЕЭЗ, так что прямой доступ возможен лишь через VPN и регистрацию за пределами РФ.\nИнтересный факт: в техническом отчёте (arXiv) описано, что модель демонстрирует почти 100 % recall на длинных контекстах до 10 миллионов токенов — это действительно прорыв в области LLM с мультимодальной обработкой.\nGemini 1.5 — это новый вектор в развитии масштабных моделей: исключительная ёмкость контекста, мультимодальность, экономия ресурсов и высокая производительность. Несмотря на ограниченный доступ в России, специалисты и компании уже активно готовят к нему интеграции в будущее.",
        "source": "https://gemini.google.com",
        "media": [
            {
                "type": "iframe",
                "src": "https://vkvideo.ru/video_ext.php?oid=-188914228&id=456239291&hd=2&autoplay=0",
                "title": "Обзор Gemini Ultra"
            },
            {
                "type": "image",
                "src": "media/geminiScreenshot1.png",
                "alt": "Промо интерфейса."
            },
            {
                "type": "image",
                "src": "media/geminiScreenshot2.png",
                "alt": "Промо интерфейса."
            },
            {
                "type": "image",
                "src": "media/geminiScreenshot3.png",
                "alt": "Промо интерфейса."
            },
            {
                "type": "image",
                "src": "media/geminiScreenshot4.jpg",
                "alt": "Эффективность Gemini по сравнению с другими нейросетями."
            }
        ]
    },
        {
        "name": "Mistral",
        "description":"Открытые LLM от французской компании Mistral AI, демонстрируют хорошую эффективность и доступны для локального развертывания.",
        "text": "Mistral — молодая, но стремительно набирающая силу европейская компания из Франции, основанная в апреле 2023 года бывшими исследователями Google DeepMind и Meta. Цель — предложить открытую и эффективную альтернативу доминирующим американским ИИ‑гигантам. Уже начальный портфель включал компактные модели вроде Mistral 7B и Mixtral 8x7B, которые при гораздо меньшем объёме (всего 7–8 млрд параметров) превосходили LLaMA‑2 13B и GPT‑3.5 по ряду задач . Это стало ярким примером того, как продуманный дизайн и оптимизированная архитектура могут превзойти чистое масштабирование. С тех пор Mistral расширила линейку: появились Mistral Large 2 (123 млрд параметров) — флагманский открытый LLM под лицензией Mistral Research и Pixtral Large — мультимодальный вариант с визуальным энкодером.\nВ марте 2025 года были выпущены модели Mistral Small 3.1 и Mistral Medium 3, а в июне представлена семейство Magistral — первые в Европе reasoning‑модели с chain‑of‑thought, доступные частично открыто: Magistral Small (с открытыми весами) и коммерческий Magistral Medium.\nТехнологическая особенность — смесь экспертов (MoE): модель выбирает узкий специализированный эксперт для конкретного запроса, что резко повышает эффективность и снижает затраты во время вывода . Именно за счёт этого даже облегчённые модели (Mixtral) дают мощь GPT‑пути по значительно меньшим ресурсным затратам.\nMistral активно продвигается в корпоративную и государственную среду: через партнёрства с Microsoft (доступ через Azure), Orange, IBM и другими — модель Le Chat уже запустили как чат‑бот и мобильное приложение, которое быстро скачали более миллиона раз. Запущена премиум‑подписка Le Chat Pro за $14,99, включающая доступ к передовым моделям и веб‑поиску.\nС точки зрения инфраструктуры, Mistral инвестирует в собственные дата‑центры во Франции на сотни мегаватт — стремясь сохранить контроль над оборудованием и соответствовать местным экологическим и регулировочным стандартам. Это важный шаг для укрепления европейского суверенитета в ИИ‑инфраструктуре.\nОдной из важнейших миссий Mistral является открытость: многие модели (Mistral Small, Mixtral, Magistral Small) распространяются с открытыми весами и под лицензией Apache‑2.0 или Research, что позволяет компаниям и исследователям модифицировать и разворачивать их локально, соблюдая GDPR. Такой подход высоко ценится в банковской сфере, здравоохранении и госсекторе.\nСреди пользователей отмечают и уникальные преимущества: скорость — до 1100 слов в секунду, что примерно в 10 раз быстрее ChatGPT и Claude, по отзывам на Reddit ; гибкость — возможность развёртывания как в облаке, так и на предприятии; а также интеграция с API и инструментариями через платформу La Plateforme — с тонкой настройкой, мониторингом, функцией function‑calling и безопасностью.\nЧто касается доступности в России, официального присутствия нет: веб‑версия Le Chat и Pro‑подписка недоступны для россиян без VPN. Открытое распространение моделей может позволить развёртывание локально, но официальной поддержки и региональных партнёрств с российскими провайдерами — пока нет.\nИнтересный факт: решение сосредоточиться на сочетании эффективности + открытости + европейской инфраструктуры дало Mistral возможность сформировать устойчивую экосистему в критически важной нише — где режим провайдерского доверия и суверенности данных играет ключевую роль.\nВ итоге Mistral — это не просто стартап, это символ новой европейской волны ИИ: компактные, но сложные модели, открытая философия, акцент на privacy и технологии Suomi — и всё это с прицелом на глобальный рынок. Несмотря на ограниченный доступ из России, проект остаётся одним из главных игроков, за которыми стоит следить.",
        "source": "https://mistral.ai/",
        "media": [
            {
                "type": "iframe",
                "src": "https://vkvideo.ru/video_ext.php?oid=-48265019&id=456242740&hd=2&autoplay=0",
                "title": "Обзор Mistral"
            },
            {
                "type": "image",
                "src": "media/mistralScreenshot1.jpg",
                "alt": "Эффективность Mistral по сравнению с другими нейросетями."
            }
        ]
    },
    {
        "name": "LLaMA 3",
        "description":"Cвободно распространяемые языковые модели, применяются в научных и прикладных целях.",
        "text": "LLaMA 3 — это третье поколение семейства крупных языковых моделей от Meta, официально представленное в апреле 2024 года. Архитектурно это декодерный трансформер следующей генерации, рассчитывающий на огромную обучающую выборку — около 15 триллионов токенов текста, что в семь раз больше, чем у LLaMA 2, и охватывающую более 30 языков. Первая версия включала лёгкие и средние модели с 8B и 70B параметрами, а в июле 2024 была выпущена флагманская LLaMA 3.1 на 405 млрд параметров. Это позволило ей соперничать с закрытыми лидерами рынка — GPT‑4o и Claude 3 Sonnet — по множеству бенчмарков, включая задачи математики, логики и генерации кода.\nОдной из ключевых особенностей LLaMA 3 стало расширение контекстного окна до 128 000 токенов, что позволяет модели работать с длинными документами, кодом, диалогами и даже целыми книгами без потери связности. Её также оснастили продвинутым токенизатором, технологией grouped query attention (GQA) для ускорения вывода и улучшения эффективности, а также системой фильтрации генераций — LLaMA Guard 2, CyberSecEval и Code Shield.\nВ общей практике LLaMA 3 демонстрирует высокую точность в задачах проверки знаний (MMLU–79.5%), генерации кода и диалога, значительно превосходя LLaMA 2 и зачастую выравниваясь по качеству с GPT‑4‑классом моделей . Младшие модели с 8B параметрами легко переигрывают аналогичные по размеру модели от Mistral и Google.\nС точки зрения экосистемы, Meta распространяет LLaMA 3 под «Community License»: модели доступны бесплатно для исследователей и бизнеса с некоторыми ограничениями (например, особые условия при внедрении для пользовательских баз свыше 700 млн), а их веса выложены на Hugging Face и Github. Существуют открытые мультимодальные версии (например, LLaMA 3.2 с визуальным энкодером), хотя они менее мощные, чем основные текстовые модели.\nLLaMA 3 уже активно используется внутри Meta: в чат‑ассистенте Meta.ai, а также интегрирована в Facebook, Instagram и WhatsApp. Кроме того, благодаря открытому доступу, модель внедряется стартапами и частными проектами по всему миру, заметно ускорив развитие open‑source LLM‑сообщества.\nВ России официально доступ ограничен — модель можно получить через международные репозитории вроде Hugging Face, но прямой локальной поддержки, интеграций или партнёрств с российскими облачными провайдерами пока нет. Как и с другими зарубежными проектами, для загрузки и использования весов требуется VPN или обход региональных ограничений.\nИнтересный момент: вес моделей LLaMA 3.3 (релиз декабрь 2024) позволил существенно снизить размер до 70B при сохранении качества, что сделало технологию доступной даже на обычных серверных машинах — развитие quantized и оптимизированных версий открывает путь к массовому распространению мощных LLM в бизнесе и промышленности.\nВ общем, LLaMA 3 — это мощная, масштабируемая и открытая модель нового поколения, сочетающая высокую производительность, поддержку длинного контекста, безопасность и удобство использования. Благодаря открытому распространению, её роль в формировании глобальной экосистемы ИИ продолжает расти — хотя в России, как и во многих странах, остаются свои ограничения на доступ.",
        "source": "https://www.llama.com/?ref=billtalksai.com",
        "media": [
            {
                "type": "iframe",
                "src": "https://vkvideo.ru/video_ext.php?oid=-226922990&id=456239063&hd=2&autoplay=0",
                "title": "Гайд, как установить LLaMA 3"
            }
        ]
    },
        {
        "name": "DALL·E 3",
        "description":"Генерация изображений по текстовому описанию.",
        "text": "DALL·E 3 — это последняя версия генератора изображений от OpenAI, появившаяся в октябре 2023 года и встроенная напрямую в ChatGPT Plus и Enterprise. В основе лежит улучшенная диффузионная архитектура, усиленная технологией ChatGPT: теперь модель автоматически переписывает ваши запросы на более детализированные благодаря GPT‑4, что значительно упрощает подбор нужных образов.\nПоявление DALL·E 3 стало прорывным по нескольким направлениям. Первое – качество интерпретации: модель внимательнее относится к деталям запроса, лучше отображает тонкие нюансы, включая текст в изображениях, выражение лиц и мелкие объекты . Второе — удобство работы: можно сначала описать идею простыми словами, а затем через ChatGPT формировать точное, подробное описание изображения, как будто обсуждаешь с художником. Третье — формат и стиль: DALL·E 3 поддерживает несколько разрешений (1024×1024, 1792×1024, 1024×1792) и два стилистических режима — «vivid» для кинематографичности и «natural» для более реалистичной передачи.\nБезопасность — ещё одна сильная сторона этой модели. Встроенные фильтры не позволят сгенерировать насилие, порнографию, изображения известных людей или стили живущих художников, чтобы не нарушать авторские права . OpenAI также внедрила систему provenance classifier, способную с большой вероятностью идентифицировать изображения, созданные ИИ, даже если они были изменены после генерации.\nС технической точки зрения, DALL·E 3 обучалась на сотнях миллионов изображений, снабжённых улучшенными подписями от GPT‑4V, что повысило точность ассоциации между текстом и визуалом . Процесс создания состоит из переписанного GPT‑4 промпта, подающегося в диффузионную модель, после чего результат можно корректировать в том же чате: «больше света», «добавить фонарик» — ChatGPT понимает и обновляет изображение.\nЧто важно знать сегодня: в ChatGPT Free каждый пользователь может генерировать до двух изображений с DALL·E 3 в день, а подписчики Plus получают безлимитный доступ (в API и чатах).\nДоступность в России. DALL·E 3 доступна через ChatGPT без региональных ограничений — нужно просто оформить подписку Plus или Enterprise и пользоваться через openai.com. Однако напрямую API-интеграция может требовать использования VPN и обхода географических ограничений — в некоторых корпоративных сценариях доступ ещё ограничен.\nНа практике DALL·E 3 отлично подходит для дизайнеров, маркетологов, иллюстраторов, педагогов и просто креативных людей. Модель позволяет быстро превращать идеи в изображения, редактировать их, генерировать логотипы, иллюстрации, визуальные материалы для презентаций и контента — всё без глубоких знаний в генеративных алгоритмах. В целом, DALL·E 3 — это мощный, простой и безопасный инструмент для визуального творчества, который выводит генерацию изображений на уровень диалога: вы говорите свою идею, модель уточняет детали, создаёт высококачественное изображение — и вы можете сразу же попросить изменения, как у живого художника.",
        "source": "https://openai.com/index/dall-e-3/",
        "media": [
            {
                "type": "iframe",
                "src": "https://vkvideo.ru/video_ext.php?oid=26308175&id=456239878&hd=2&autoplay=0",
                "title": "Обзор DALL-E 3"
            },
            {
                "type": "image",
                "src": "media/dalleScreenshot1.png",
                "alt": "Сравнение примеров работ нейросетей."
            },
            {
                "type": "image",
                "src": "media/dalleScreenshot2.jpeg",
                "alt": "Сравнение примеров работ нейросетей."
            },
            {
                "type": "image",
                "src": "media/dalleScreenshot3.png",
                "alt": "Главная страница."
            }
        ]
    },
    {
        "name": "Midjourney",
        "description":"Нейросеть с выдающимся качеством генерации художественных изображений.",
        "text": "Midjourney – это одна из самых известных и творчески ориентированных систем генерации изображений, запущенная в июле 2022 года. В отличие от многих инструментов, Midjourney изначально была доступна только через Discord‑бота, что придаёт ей дух сообщества и экспериментальности. Пользователю достаточно подключиться к официальному серверу Midjourney или пригласить бота к себе, оплатить одну из подписок – от базовой до мегатарифа – и отправить команду /imagine с текстовым описанием изображения. Через минуты появляется четыре версии, из которых можно выбрать понравившуюся, увеличить её детализацию, сгенерировать вариации или «перебросить» команды заново.\nВеб‑версия стала доступна позже: пользователям, создавшим более 100 картинок, открыли редактор, который позволяет управлять изображением напрямую — зум, обрезка, инпэйнтинг и создание вариаций теперь можно делать в браузере . Это значительно упростило вход в систему для художников и дизайнеров.\nЧто касается технологии, Midjourney сочетает языковую модель для понимания промптов с диффузионной моделью для генерации картинок: текст переводится в численный вектор, который управляет процессом «очистки шума» из случайного поля, приводя к формированию изображения, отвечающего запросу . Модель обучена на широчайших датасетах произведений искусства, фотографий, графики. Благодаря изучению стилистических и композиционных паттернов она не просто копирует известные сюжеты — Midjourney создаёт уникальные визуальные решения, подражая стилю, а не конкретным художникам.\nОсобенности разных версий модели (например, V5.2, V6 и сейчас V7) предоставляют разную степень творческого риска: там, где ChatGPT и DALL·E стремятся к точности, Midjourney часто готова плыть в сторону абстракции или неожиданной эстетики. Это делает работу с ней особенно захватывающей: на выходе — сюрреалистичные сцены, художественные композиции и фантазийные миры, при этом требуется от пользователя участие: игра со стилями, ввод параметров вроде --stylize, --chaos, выбор вариативности и скорости генерации.\nЗа месяцы работы над V7 Midjourney значительно улучшила текстуры, лицо и мех — но уступает по стабильности детализации там, где нужны реалистичные руки или текст на картинке . При этом скорости генерации ростут, интерфейс становится интуитивнее, а возможности — шире: от in‑paint до «Patchwork» — живого холста для рассказывания историй директно в вебе.\nПлагином сообщества, Midjourney снабжена мощной модерацией: запрещены насилие, оскорбления, дипфейки, что позволяет безопасно генерировать контент даже в строгих юрисдикциях. Всё это — за подписку от $10 до $120 в месяц, с ограничением по GPU‑времени, приватным режимом (Stealth Mode) на верхних планах и возможностью генерации в ускоренном или обычном режиме.\nЧто касается доступности в России, официальный доступ к Midjourney возможен — подписка оплачивается в долларах, интерфейс Discord доступен без VPN, а веб‑редактор работает в браузере. Однако высокая цена и ограниченные GPU‑часы делают использование дорогим, особенно при пересчёте курса . Также могут возникать сложности с оплатой картами, выпущенными российскими банками, и редкими перебоями с доступом к зарубежным серверам.\nИнтересный факт: в июне 2025 года Disney и Universal подали в суд на Midjourney, обвиняя её в системном нарушении авторских прав и создании изображений популярных персонажей — это один из первых громких кейсов, который может повлиять на будущее всех генераторов изображений.\nВ результате, Midjourney — это инструмент для тех, кто хочет не просто получить картинку, а участвовать в творческом процессе: смешивать стили, исследовать «латентное» пространство идей, пробовать и наблюдать неожиданные результаты. Это не «точный художник по поручению», а соавтор, провоцирующий, удивляющий и вдохновляющий — что делает её уникальной на фоне других AI‑генераторов, и делает работу с ней увлекательной игрой воображения.",
        "source": "https://www.midjourney.com/home",
        "media": [
            {
                "type": "iframe",
                "src": "https://vkvideo.ru/video_ext.php?oid=-214454387&id=456239825&hd=2&autoplay=0",
                "title": "Обзор и начало работы с Midjourney"
            },
            {
                "type": "image",
                "src": "media/midjourneyScreenshot1.jpg",
                "alt": "Примеры работы нейросети. Сгенерированные изображения."
            },
            {
                "type": "image",
                "src": "media/midjourneyScreenshot2.jpg",
                "alt": "Подборка сгенерированных изображений на странице Midjourney."
            },
            {
                "type": "image",
                "src": "media/midjourneyScreenshot3.png",
                "alt": "Подборка сгенерированных изображений на странице Midjourney."
            },
            {
                "type": "image",
                "src": "media/midjourneyScreenshot4.png",
                "alt": "Сравнение версий нейросети по примерам работ."
            }
        ]
    },
    {
        "name": "Stable Diffusion",
        "description":"Открытая модель для генерации изображений, активно развивается сообществом.",
        "text": "Stable Diffusion — это одна из самых популярных и гибких нейросетей для генерации изображений по текстовому описанию. Она появилась в августе 2022 года и сразу же изменила ландшафт генеративного искусства, став первой мощной ИИ-моделью с открытым исходным кодом. В отличие от таких закрытых решений, как Midjourney или DALL·E, Stable Diffusion можно запускать локально на домашнем компьютере или сервере, что делает её особенно привлекательной для разработчиков, художников, исследователей и энтузиастов, желающих иметь полный контроль над процессом генерации и своими данными.\nЧтобы воспользоваться Stable Diffusion, нужно установить модель через один из популярных графических интерфейсов, например Automatic1111 WebUI, ComfyUI, NMKD GUI или InvokeAI. Установка может показаться сложной новичкам, но благодаря большому сообществу и множеству видеоуроков на русском языке процесс стал достаточно доступным. Также существуют облачные версии вроде Stability.ai (DreamStudio), RunDiffusion, Mage.space и Leonardo.ai, где можно генерировать изображения прямо в браузере без установки. Пользователь просто вводит промпт — текстовое описание изображения — а нейросеть создаёт картинку, которую можно доработать через параметры или редактирование.\nНа техническом уровне Stable Diffusion — это латентная диффузионная модель. В отличие от классической генерации из пиксельного шума, она сначала переводит изображение в абстрактное скрытое пространство (латентное представление), где и происходит «очистка шума» в процессе создания изображения. Это значительно ускоряет генерацию и снижает требования к ресурсам. Модель обучалась на огромном наборе изображений LAION-5B, что позволило ей распознавать множество объектов, стилей, композиций и визуальных ассоциаций. Алгоритм основан на архитектуре U-Net и вариациях CLIP от OpenAI, который помогает сопоставлять текст и изображение.\nОдним из главных достоинств Stable Diffusion стала её открытость: пользователи могут менять модели, дообучать их на своих данных, использовать LoRA-модули, DreamBooth, Textual Inversion — всё это даёт практически безграничные возможности кастомизации. Можно загрузить модель, которая «умеет» рисовать в стиле аниме, ренессансной живописи или в стилистике конкретного художника. Это делает Stable Diffusion идеальной платформой для создания AI-аватаров, комиксов, концепт-артов, логотипов, иллюстраций и даже научных изображений. Возможны режимы img2img (генерация из наброска или фотографии), inpainting (редактирование области в картинке) и контроль с помощью ControlNet — отдельной модели, позволяющей точно задавать позу, глубину, карту освещения или сегментацию.\nПо мере развития Stable Diffusion претерпела несколько важных версий. Оригинальная модель 1.4 быстро сменилась на 1.5, а затем вышла 2.0 и 2.1. Последние версии дают более реалистичные результаты, но требуют более точных промптов и хуже справляются с лицами без донастройки. В мае 2024 года Stability.ai выпустила SDXL — новую архитектуру с гораздо лучшей проработкой деталей, поддержкой более длинных промптов и более кинематографичным качеством генерации. SDXL стала новой вехой, способной конкурировать по качеству с Midjourney и DALL·E 3, при этом оставаясь полностью открытой.\nОтдельный интерес представляет экосистема вокруг Stable Diffusion. Тысячи LoRA-файлов и чекпойнтов выкладываются на платформах вроде Civitai и HuggingFace. Люди делятся своими стилями, тренировками, наработками, благодаря чему даже новичок может получить уникальные визуальные стили без навыков программирования. Также активно развивается генерация видео и 3D, и на базе SDXL создаются гибридные решения, в которых картинки оживают, двигаются или конвертируются в объемные модели.\nВ России Stable Diffusion доступна без ограничений. Её можно установить локально и использовать полностью оффлайн, что делает её идеальным выбором в условиях ограниченного интернета или невозможности пользоваться западными сервисами. Многие художники, дизайнеры и студии уже используют её для прототипирования, обложек, презентаций и коммерческого творчества. Платформы вроде СберАИ и Neuronet также строят локальные решения, вдохновляясь архитектурой Stable Diffusion. Более того, при желании модель можно запустить даже на видеокартах среднего уровня — например, на RTX 3060, — что делает её доступной широкой аудитории.\nИнтересный факт: благодаря своей открытости Stable Diffusion стала объектом юридических споров. Компании Getty Images и другие подали иски, обвиняя разработчиков в использовании несанкционированных изображений при обучении. Однако это не помешало росту популярности модели, наоборот — привлекло ещё больше внимания к вопросу этики и легальности в ИИ-искусстве. Это также спровоцировало появление проектов по обучению моделей на полностью лицензированных или созданных вручную датасетах.\nТаким образом, Stable Diffusion — это не просто генератор изображений, а целая платформа для визуального творчества, открытых экспериментов и локального управления. Она идеально подойдёт тем, кто хочет исследовать возможности генеративного ИИ глубже, настраивать модель под себя, строить собственные стили и не зависеть от внешних серверов. И, что важно, её можно свободно использовать в России — как для хобби, так и в коммерческих целях.",
        "source": "https://stabledifffusion.com/ru/tools/ai-image-generator",
        "media": [
            {
                "type": "iframe",
                "src": "https://vkvideo.ru/video_ext.php?oid=-211194784&id=456239088&hd=2&autoplay=0",
                "title": "Обзор нейросети Stable Diffusion 3.5"
            },
            {
                "type": "image",
                "src": "media/SDscreenshot1.png",
                "alt": "Сравнение примеров работ нейросетей."
            },
            {
                "type": "image",
                "src": "media/SDscreenshot2.png",
                "alt": "Экран настройки промпта."
            },
            {
                "type": "image",
                "src": "media/SDscreenshot3.png",
                "alt": "Архитектура нейросети."
            }
        ]
    },
    {
        "name": "ElevenLabs",
        "description":"Качественная генерация речи с сохранением интонации и акцента.",
        "text": "ElevenLabs возникла в 2022 году как стартап, основанный бывшими сотрудниками Google и Palantir, и уже в начале 2023-го привлекла внимание как один из самых реалистичных генераторов речи. Платформа специализируется на преобразовании текста в звук (Text‑to‑Speech), создании голосовых клонов, переводе (dubbing), а также преобразовании речи в текст (Speech‑to‑Text). Пользователи могут начать работу через веб‑интерфейс, где достаточно вставить текст, выбрать голос или оплатить загрузку собственной голосовой записи, и получить аудиофайл студийного качества с интеллектуальной интонацией, эмоциями и паузами. Чем ElevenLabs выделяется — это выразительность голоса. Модель понимает контекст и эмоциональный фон текста, что позволяет давать голосу оттенок тревоги, радости, сарказма, и даже имитировать акцент — на русском доступны региональные варианты. Для разработчиков платформа предлагает недорогой и быстрый API с задержкой порядка 75–400 мс, SDK для Python и TypeScript, а также масштабируемость для массовых применений — подкасты, звонки, чат‑боты и озвучка видео.\nПод капотом ElevenLabs работает сложная нейросетевая инфраструктура: сначала текст разбивается на фонемы и синтакс·емы, затем в процессе speech synthesis генератор формирует аудиодорожку, управляя тоном, интонацией и паузой. Особое внимание уделяется точности произношения имен, что зачастую является проблемой у других TTS-систем. С выходом версии Eleven v3 (июнь 2025) платформа расширила поддержку более 70 языков, добавила многоголосую простоту диалога и метки аудио-эмоций вроде [excited], [whispers], [sighs].\nИнфраструктурно ElevenLabs предлагает разные пакеты: бесплатный план предусматривает ~10 000 символов в месяц, для начинающих, а расширенные тарифы — до миллионов символов и приоритетную поддержку. Enterprise‑решения включают гибкие PKI, локальные развёртывания, SLA и интеграции с контакт‑центрами, издателями, студиями и др.\nПлатформа пишет, что она соблюдает стандарты GDPR и SOC II, а также содержит встроенные механизмы модерации, отслеживания использования и фильтрации вредоносного или незаконного контента. Предложен даже инструмент – AI Speech Classifier, способный определить, генерировано ли конкретное аудио самим ElevenLabs.\nС точки зрения доступности в России, платформа блокирована — российские IP‑адреса не получают к ней доступ. Это косвенно означает, что без VPN или иных обходных методов пользоваться ней официально невозможно. Даже облачный сервер за пределами РФ может быть по ошибке заблокирован, если определяется как «российский», и пользователю предлагается сменить IP.\nВ целом, ElevenLabs — это эталонно‑выразительный TTS‑двигатель, сочетающий широкую языковую поддержку, кастомизацию голосов, низкую задержку и продвинутый API. Это лучший выбор для создателей аудио‑контента, разработчиков голосовых систем и всех, кому важно передать содержание и эмоциональный посыл через голос. Но при этом его использование требует обхода блокировок в некоторых регионах, включая Россию, и тщательной этической оценке для избежания misuse.",
        "source": "https://elevenlabs.io/?pscd=try.elevenlabs.io&ps_partner_key=dmlyZ2lsYmFhbDY4NjA&ps_xid=zZI1LQ7TtdUVJ0&gsxid=zZI1LQ7TtdUVJ0&gspk=dmlyZ2lsYmFhbDY4NjA",
        "media": [
            {
                "type": "iframe",
                "src": "https://vkvideo.ru/video_ext.php?oid=-224793167&id=456239150&hd=2&autoplay=0",
                "title": "Обзор Eleven Labs"
            }
        ]
    }
]